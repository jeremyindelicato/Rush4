{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ Suivi du Projet Machine Learning - Segmentation Clients\n",
    "## Pr√©diction de R√©ponse aux Campagnes Marketing\n",
    "\n",
    "**Objectif :** Construire un mod√®le pr√©dictif pour pr√©dire la probabilit√© qu'un client r√©ponde √† une campagne future.\n",
    "\n",
    "**Dataset :** ML_DataSet.csv (2237 clients √ó 49 features)\n",
    "\n",
    "**Cible :** Reponse_Derniere_Campagne (0/1)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Phase 1 : Exploration et Pr√©paration des Donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports n√©cessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"‚úÖ Biblioth√®ques import√©es avec succ√®s\")\n",
    "print(f\"üìÖ Date de derni√®re mise √† jour : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du dataset\n",
    "df = pd.read_csv('ML_DataSet.csv')\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"INFORMATIONS G√âN√âRALES DU DATASET\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Nombre de lignes (clients) : {df.shape[0]}\")\n",
    "print(f\"Nombre de colonnes (features) : {df.shape[1]}\")\n",
    "print(f\"Taille m√©moire : {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "# Aper√ßu des donn√©es\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Analyse de la Variable Cible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution de la variable cible\n",
    "target_col = 'Reponse_Derniere_Campagne'\n",
    "target_dist = df[target_col].value_counts()\n",
    "target_pct = df[target_col].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DISTRIBUTION DE LA VARIABLE CIBLE\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Variable : {target_col}\\n\")\n",
    "for classe in sorted(df[target_col].unique()):\n",
    "    count = target_dist[classe]\n",
    "    pct = target_pct[classe]\n",
    "    print(f\"  Classe {classe} : {count:4d} clients ({pct:.2f}%)\")\n",
    "\n",
    "ratio_desequilibre = target_dist[0] / target_dist[1]\n",
    "print(f\"\\n‚ö†Ô∏è  Ratio de d√©s√©quilibre : {ratio_desequilibre:.2f}:1\")\n",
    "if ratio_desequilibre > 3:\n",
    "    print(\"   ‚Üí D√©s√©quilibre IMPORTANT d√©tect√©\")\n",
    "    print(\"   ‚Üí Strat√©gie recommand√©e : scale_pos_weight, class_weight, ou SMOTE\")\n",
    "\n",
    "# Visualisation\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Barplot\n",
    "axes[0].bar(['Non (0)', 'Oui (1)'], target_dist.values, color=['#e74c3c', '#2ecc71'])\n",
    "axes[0].set_title('Distribution de la Variable Cible', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Nombre de clients')\n",
    "axes[0].set_xlabel('R√©ponse √† la campagne')\n",
    "for i, v in enumerate(target_dist.values):\n",
    "    axes[0].text(i, v + 30, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "# Pie chart\n",
    "colors = ['#e74c3c', '#2ecc71']\n",
    "axes[1].pie(target_dist.values, labels=['Non (0)', 'Oui (1)'], autopct='%1.1f%%', \n",
    "            startangle=90, colors=colors, textprops={'fontsize': 12, 'fontweight': 'bold'})\n",
    "axes[1].set_title('Proportion des R√©ponses', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Analyse de la variable cible termin√©e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìã S√©lection des Features pour le Mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colonnes √† exclure du mod√®le\n",
    "colonnes_a_exclure = [\n",
    "    'ID_Client',                      # Identifiant\n",
    "    'Annee_Naissance',                # Redondant avec Age_Inscription\n",
    "    'Date_Inscription',               # Format date, redondant avec Jour_Inscription_Encode\n",
    "    'Niveau_Education',               # Redondant avec Niveau_Education_Encode\n",
    "    'Statut_Marital',                 # Redondant avec Statut_Marital_Encode\n",
    "    'Statut_Marital_Texte',           # Redondant\n",
    "    'Jour_Inscription',               # Redondant avec Jour_Inscription_Encode\n",
    "    'Categorie_Age',                  # Redondant avec Categorie_Age_Encode\n",
    "    'Cout_Contact_Z',                 # Constante (toujours 3)\n",
    "    'Revenus_Z',                      # Constante (toujours 11)\n",
    "    'Reponse_Derniere_Campagne',     # TARGET (√† extraire s√©par√©ment)\n",
    "    'Enfants_Maison',                 # Redondant avec Total_Enfants\n",
    "    'Ados_Maison'                     # Redondant avec Total_Enfants\n",
    "]\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PR√âPARATION DES FEATURES\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nColonnes totales : {len(df.columns)}\")\n",
    "print(f\"Colonnes √† exclure : {len(colonnes_a_exclure)}\")\n",
    "print(f\"Colonnes pour le mod√®le : {len(df.columns) - len(colonnes_a_exclure)}\")\n",
    "\n",
    "# Cr√©er X et y\n",
    "X = df.drop(columns=colonnes_a_exclure)\n",
    "y = df['Reponse_Derniere_Campagne']\n",
    "\n",
    "print(f\"\\n‚úÖ X shape : {X.shape}\")\n",
    "print(f\"‚úÖ y shape : {y.shape}\")\n",
    "\n",
    "print(\"\\n--- FEATURES S√âLECTIONN√âES ---\")\n",
    "for i, col in enumerate(X.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")\n",
    "\n",
    "# V√©rifier les valeurs manquantes\n",
    "missing = X.isnull().sum()\n",
    "if missing.sum() > 0:\n",
    "    print(\"\\n‚ö†Ô∏è  Valeurs manquantes d√©tect√©es :\")\n",
    "    print(missing[missing > 0])\n",
    "else:\n",
    "    print(\"\\n‚úÖ Aucune valeur manquante d√©tect√©e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Statistiques Descriptives des Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques descriptives\n",
    "print(\"=\" * 70)\n",
    "print(\"STATISTIQUES DESCRIPTIVES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "X.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç Analyse de Corr√©lation avec la Cible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corr√©lation avec la variable cible\n",
    "df_with_target = X.copy()\n",
    "df_with_target['Target'] = y\n",
    "\n",
    "correlations = df_with_target.corr()['Target'].drop('Target').sort_values(ascending=False)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TOP 15 FEATURES CORR√âL√âES AVEC LA CIBLE\")\n",
    "print(\"=\" * 70)\n",
    "print(correlations.head(15))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TOP 15 FEATURES N√âGATIVEMENT CORR√âL√âES\")\n",
    "print(\"=\" * 70)\n",
    "print(correlations.tail(15))\n",
    "\n",
    "# Visualisation\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "top_features = pd.concat([correlations.head(10), correlations.tail(10)])\n",
    "colors = ['green' if x > 0 else 'red' for x in top_features.values]\n",
    "top_features.plot(kind='barh', ax=ax, color=colors)\n",
    "ax.set_title('Top 20 Features par Corr√©lation avec la Cible', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Corr√©lation de Pearson')\n",
    "ax.axvline(x=0, color='black', linestyle='-', linewidth=0.8)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Analyse de corr√©lation termin√©e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ü§ñ Phase 2 : Construction et √âvaluation des Mod√®les\n",
    "\n",
    "### Mod√®les √† tester :\n",
    "1. **R√©gression Logistique** (baseline)\n",
    "2. **Random Forest** (robuste)\n",
    "3. **XGBoost** (champion attendu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports pour le machine learning\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    roc_auc_score, \n",
    "    roc_curve,\n",
    "    precision_recall_curve,\n",
    "    f1_score,\n",
    "    accuracy_score\n",
    ")\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    xgboost_available = True\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è  XGBoost non install√©. Installer avec : pip install xgboost\")\n",
    "    xgboost_available = False\n",
    "\n",
    "print(\"‚úÖ Biblioth√®ques ML import√©es avec succ√®s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîÄ Split Train/Test avec Stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split stratifi√© (important pour le d√©s√©quilibre)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y  # Maintient les proportions\n",
    ")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"SPLIT TRAIN/TEST\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Train set : {X_train.shape[0]} clients ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Test set  : {X_test.shape[0]} clients ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nDistribution dans Train set :\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"Ratio : {y_train.value_counts()[0] / y_train.value_counts()[1]:.2f}:1\")\n",
    "\n",
    "print(\"\\nDistribution dans Test set :\")\n",
    "print(y_test.value_counts())\n",
    "print(f\"Ratio : {y_test.value_counts()[0] / y_test.value_counts()[1]:.2f}:1\")\n",
    "\n",
    "# Normalisation (utile pour R√©gression Logistique)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\n‚úÖ Donn√©es pr√©par√©es pour l'entra√Ænement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Fonction d'√âvaluation des Mod√®les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluer_modele(model, X_train, X_test, y_train, y_test, nom_modele):\n",
    "    \"\"\"\n",
    "    √âvalue un mod√®le et affiche les m√©triques compl√®tes\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"√âVALUATION : {nom_modele}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Entra√Ænement\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Pr√©dictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # M√©triques\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    print(f\"\\nüìä M√©triques Globales :\")\n",
    "    print(f\"  Accuracy  : {accuracy:.4f}\")\n",
    "    print(f\"  F1-Score  : {f1:.4f}\")\n",
    "    print(f\"  ROC-AUC   : {roc_auc:.4f}\")\n",
    "    \n",
    "    print(f\"\\nüìã Rapport de Classification :\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Non (0)', 'Oui (1)']))\n",
    "    \n",
    "    # Matrice de confusion\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Matrice de confusion\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "                xticklabels=['Non (0)', 'Oui (1)'],\n",
    "                yticklabels=['Non (0)', 'Oui (1)'])\n",
    "    axes[0].set_title(f'Matrice de Confusion - {nom_modele}', fontweight='bold')\n",
    "    axes[0].set_ylabel('Vraie Classe')\n",
    "    axes[0].set_xlabel('Classe Pr√©dite')\n",
    "    \n",
    "    # Courbe ROC\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    axes[1].plot(fpr, tpr, label=f'{nom_modele} (AUC = {roc_auc:.3f})', linewidth=2)\n",
    "    axes[1].plot([0, 1], [0, 1], 'k--', label='Al√©atoire (AUC = 0.5)')\n",
    "    axes[1].set_xlabel('Taux de Faux Positifs')\n",
    "    axes[1].set_ylabel('Taux de Vrais Positifs')\n",
    "    axes[1].set_title(f'Courbe ROC - {nom_modele}', fontweight='bold')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1,\n",
    "        'roc_auc': roc_auc,\n",
    "        'y_pred': y_pred,\n",
    "        'y_pred_proba': y_pred_proba\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Fonction d'√©valuation cr√©√©e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ √Ä COMPL√âTER : Entra√Ænement des Mod√®les\n",
    "\n",
    "### Mod√®le 1 : R√©gression Logistique (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entra√Æner et √©valuer la R√©gression Logistique\n",
    "# modele_lr = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
    "# resultats_lr = evaluer_modele(modele_lr, X_train_scaled, X_test_scaled, y_train, y_test, \"R√©gression Logistique\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mod√®le 2 : Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entra√Æner et √©valuer Random Forest\n",
    "# modele_rf = RandomForestClassifier(n_estimators=100, max_depth=10, class_weight='balanced', random_state=42)\n",
    "# resultats_rf = evaluer_modele(modele_rf, X_train, X_test, y_train, y_test, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mod√®le 3 : XGBoost (Champion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entra√Æner et √©valuer XGBoost\n",
    "# scale_pos_weight = y_train.value_counts()[0] / y_train.value_counts()[1]\n",
    "# modele_xgb = XGBClassifier(scale_pos_weight=scale_pos_weight, max_depth=5, learning_rate=0.1, n_estimators=100, random_state=42)\n",
    "# resultats_xgb = evaluer_modele(modele_xgb, X_train, X_test, y_train, y_test, \"XGBoost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä Comparaison des Mod√®les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Comparer les performances des 3 mod√®les\n",
    "# Cr√©er un DataFrame de comparaison avec accuracy, f1_score, roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üîç Interpr√©tabilit√© : Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Afficher l'importance des features du meilleur mod√®le\n",
    "# Pour Random Forest et XGBoost : model.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìù Conclusions et Prochaines √âtapes\n",
    "\n",
    "### R√©sultats obtenus :\n",
    "- [ ] Mod√®le baseline (R√©gression Logistique) entra√Æn√©\n",
    "- [ ] Random Forest entra√Æn√©\n",
    "- [ ] XGBoost entra√Æn√©\n",
    "- [ ] Comparaison des performances effectu√©e\n",
    "- [ ] Feature importance analys√©e\n",
    "\n",
    "### Am√©liorations possibles :\n",
    "1. **Optimisation des hyperparam√®tres** (GridSearchCV, RandomizedSearchCV)\n",
    "2. **SMOTE** pour r√©√©quilibrer le dataset\n",
    "3. **Feature Engineering** suppl√©mentaire\n",
    "4. **SHAP values** pour l'interpr√©tabilit√© XGBoost\n",
    "5. **Calibration** des probabilit√©s\n",
    "6. **Ensemble methods** (stacking, voting)\n",
    "\n",
    "### Impact Business :\n",
    "- Meilleur ciblage des campagnes marketing\n",
    "- Optimisation du budget marketing\n",
    "- Augmentation du ROI des campagnes\n",
    "\n",
    "---\n",
    "\n",
    "**Date de derni√®re mise √† jour :** [√Ä compl√©ter]\n",
    "\n",
    "**Auteur :** [Votre nom]\n",
    "\n",
    "**Projet :** Rush 4 - Segmentation Clients"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
