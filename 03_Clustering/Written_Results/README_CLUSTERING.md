# üéØ Clustering - Segmentation Clients

## üìã Vue d'Ensemble

Ce dossier contient l'analyse de clustering pour segmenter la base clients en groupes homog√®nes.

**Objectif :** Identifier des segments de clients avec des comportements similaires pour adapter les strat√©gies marketing.

---

## üìÇ Contenu

| Fichier | Description | Status |
|---------|-------------|--------|
| **ML_Clustering.ipynb** | Notebook principal de clustering | ‚úÖ Pr√™t |
| **cluster_profiles.csv** | Profils export√©s des segments | (cr√©√© apr√®s ex√©cution) |

---

## üéØ M√©thodes de Clustering

### 1. **K-Means** (Principal)
- Algorithme de partition bas√© sur les centro√Ødes
- M√©thode du coude pour trouver K optimal
- M√©triques : Silhouette Score, Davies-Bouldin, Calinski-Harabasz

### 2. **Hierarchical Clustering**
- Dendrogramme pour visualiser la hi√©rarchie
- Confirmation de K optimal
- M√©thode : Ward linkage

### 3. **DBSCAN**
- D√©tection des outliers
- Clustering bas√© sur la densit√©
- Identification des clients atypiques

---

## üöÄ Comment Ex√©cuter

### Option 1 : VSCode (Recommand√©)
```bash
1. Ouvrez ML_Clustering.ipynb
2. S√©lectionnez le kernel .venv
3. Run All (ou cellule par cellule)
```

### Option 2 : Jupyter Notebook
```bash
cd "03_Clustering"
jupyter notebook ML_Clustering.ipynb
```

**Temps d'ex√©cution :** ~5-10 minutes

---

## üìä Features Utilis√©es pour le Clustering

### D√©mographiques (3)
- `Revenu`
- `Age_Inscription`
- `Total_Enfants`

### Comportement d'Achat (6)
- `Total_Depense`
- `Total_Achats`
- `Depense_Moy_Par_Achat`
- `Achat_Vins`
- `Achat_Viandes`
- `Achat_Poissons`
- `Achat_Produits_Or`

### Canaux d'Achat (3)
- `Achats_En_Ligne`
- `Achats_Catalogue`
- `Achats_En_Magasin`

### Engagement (5)
- `Visites_Web_Mois`
- `Engagement_Web`
- `Sensibilite_Promo`
- `Total_Campagnes_Acceptees`
- `Taux_Reponse_Historique`

**Total : 18 features**

---

## üìà R√©sultats Attendus

### K Optimal
D'apr√®s la m√©thode du coude et les m√©triques, **K=3 ou 4** devrait √™tre optimal.

### Segments Typiques Attendus

**Exemple avec K=4 :**

1. **Segment VIP - Gros D√©pensiers**
   - Revenu √©lev√© (>70k‚Ç¨)
   - D√©pense moyenne √©lev√©e (>1500‚Ç¨)
   - Taux de r√©ponse √©lev√© (~25-30%)
   - Pr√©f√©rence : Vins, Viandes premium

2. **Segment Digital - Jeunes Connect√©s**
   - 25-35 ans
   - Fort engagement web
   - Achats principalement en ligne
   - Sensibles aux promotions flash

3. **Segment Occasionnel - Faible Engagement**
   - D√©pense faible (<300‚Ç¨)
   - Peu d'achats
   - Faible engagement
   - Taux de r√©ponse bas (~5-10%)

4. **Segment Senior - Magasin Fid√®le**
   - 50+ ans
   - Achats principalement en magasin
   - Fid√®les mais peu digitaux
   - Taux de r√©ponse moyen (~15%)

*(√Ä ajuster selon vos r√©sultats r√©els)*

---

## üìä Visualisations Incluses

### 1. M√©thode du Coude
- Graphique Inertia vs K
- Silhouette Score vs K
- Davies-Bouldin Score vs K
- Calinski-Harabasz Score vs K

### 2. Visualisation PCA 2D
- Projection des clients en 2 dimensions
- Coloration par cluster
- Centro√Ødes affich√©s

### 3. Taux de R√©ponse par Cluster
- Barplot du taux de r√©ponse √† la campagne
- Permet d'identifier les segments les plus r√©actifs

### 4. Heatmap des Profils
- Comparaison visuelle des clusters
- Toutes les features moyennes par cluster
- Valeurs normalis√©es (0-1)

### 5. Dendrogramme
- Hierarchical clustering
- Visualisation de la hi√©rarchie des clusters

---

## üí° Comment Interpr√©ter les R√©sultats

### Silhouette Score
- **0.7 - 1.0** : Excellent (clusters bien s√©par√©s)
- **0.5 - 0.7** : Bon
- **0.25 - 0.5** : Acceptable
- **< 0.25** : Mauvais (clusters se chevauchent)

### Davies-Bouldin Score
- **Plus bas = meilleur**
- Mesure la s√©paration entre clusters
- Valeur typique : 0.5 - 2.0

### Calinski-Harabasz Score
- **Plus √©lev√© = meilleur**
- Ratio de la dispersion inter-cluster / intra-cluster
- Valeur typique : > 100

---

## üéØ Utilisation des R√©sultats

### 1. Marketing Cibl√©
Adapter les campagnes selon le segment :
- VIP ‚Üí Offres premium
- Digital ‚Üí Campagnes mobiles
- Occasionnel ‚Üí Promotions agressives
- Senior ‚Üí Contact t√©l√©phonique

### 2. Allocation Budget
Concentrer les ressources sur les segments √† fort ROI

### 3. Pr√©diction par Segment
Entra√Æner un mod√®le XGBoost par segment (voir `../02_Prediction/`)

### 4. Monitoring
Suivre l'√©volution des segments dans le temps

---

## üìù Naming des Segments

**‚ö†Ô∏è Important :** Une fois les clusters analys√©s, donnez-leur des **noms parlants** dans la cellule d√©di√©e du notebook.

**Exemples :**
```python
cluster_names = {
    0: "VIP - Gros D√©pensiers",
    1: "Digital Natives - Jeunes Connect√©s",
    2: "Occasionnels - Faible Engagement",
    3: "Seniors Fid√®les - Magasin"
}
```

Ces noms facilitent la communication avec les √©quipes marketing.

---

## üì§ Exports

Le notebook g√©n√®re automatiquement :

1. **cluster_profiles.csv**
   - Moyennes de toutes les features par cluster
   - Utilisable pour rapports/dashboards

2. **ML_DataSet_with_Clusters.csv** (dans `../01_Data/`)
   - Dataset complet avec colonne `Cluster_KMeans`
   - Utilisable pour analyses suppl√©mentaires

---

## üîß Ajustements Possibles

### Changer K
Modifiez la variable `K_OPTIMAL` dans la cellule correspondante :
```python
K_OPTIMAL = 3  # ou 4, 5, etc.
```

### Ajouter/Retirer des Features
Modifiez la liste `features_clustering` :
```python
features_clustering = [
    'Revenu',
    'Total_Depense',
    # ... ajoutez vos features
]
```

### Tester d'autres Algorithmes
- **DBSCAN** : D√©j√† inclus, ajustez `eps` et `min_samples`
- **Gaussian Mixture Models** : √Ä ajouter si besoin
- **Mean Shift** : Pour clustering sans K pr√©d√©fini

---

## üéì Concepts Cl√©s

### Normalisation
**CRUCIAL pour le clustering !**
- Les algorithmes sont sensibles √† l'√©chelle
- StandardScaler : (x - mean) / std
- Toutes les features ont alors mean=0, std=1

### PCA (Principal Component Analysis)
- R√©duction de dimension pour visualisation
- Les 2 premi√®res composantes capturent 30-50% de la variance
- Permet de visualiser des donn√©es multidimensionnelles en 2D

### Centro√Ødes (K-Means)
- Point moyen de chaque cluster
- Utilis√© pour assigner les nouveaux points

---

## üêõ Troubleshooting

### Erreur : "No module named 'sklearn.cluster'"
```bash
pip install scikit-learn
```

### Le clustering prend trop de temps
- R√©duisez le nombre de features
- Utilisez un √©chantillon du dataset

### Les clusters ne font pas sens
- V√©rifiez la normalisation
- Testez un autre K
- Retirez les features non pertinentes

### Silhouette Score tr√®s bas (< 0.3)
- Peut-√™tre que les donn√©es n'ont pas de structure naturelle en clusters
- Essayez d'autres valeurs de K
- V√©rifiez s'il y a des outliers √† retirer

---

## üìö Prochaines √âtapes

### Analyse Approfondie
1. Cr√©er des visualisations radar pour chaque segment
2. Analyser l'√©volution temporelle des segments
3. Croiser avec les donn√©es de campagnes

### Mod√©lisation par Segment
1. Entra√Æner un XGBoost par cluster
2. Comparer avec le mod√®le global
3. Mesurer l'am√©lioration du ROC-AUC

### Strat√©gie Marketing
1. D√©finir des actions concr√®tes par segment
2. Estimer le ROI par segment
3. Cr√©er des personas

---

## ‚úÖ Checklist

Avant de passer √† l'analyse approfondie :

- [ ] Notebook ex√©cut√© avec succ√®s
- [ ] K optimal identifi√© (probablement 3-4)
- [ ] Silhouette Score > 0.3 (acceptable)
- [ ] Segments nomm√©s avec des noms parlants
- [ ] Profils analys√©s et compris
- [ ] cluster_profiles.csv export√©
- [ ] Dataset avec clusters sauvegard√©

---

**Derni√®re mise √† jour :** 2025-10-17
**Projet :** Rush 4 - Segmentation Clients
**Responsable :** Machine Learning & Clustering
